{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Title processing\n",
      "Start find all row_data in economy\n",
      "Start find top-100 TF in economy\n",
      "Start processing co-occurrence in  economy\n",
      "Start output in  economy\n",
      "Start find all row_data in microsoft\n",
      "Start find top-100 TF in microsoft\n",
      "Start processing co-occurrence in  microsoft\n",
      "Start output in  microsoft\n",
      "Start find all row_data in palestine\n",
      "Start find top-100 TF in palestine\n",
      "Start processing co-occurrence in  palestine\n",
      "Start output in  palestine\n",
      "Start find all row_data in obama\n",
      "Start find top-100 TF in obama\n",
      "Start processing co-occurrence in  obama\n",
      "Start output in  obama\n",
      "Title output Success!\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from operator import add \n",
    "import csv\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "global Path\n",
    "Path = \"/home/ethan/pythonwork/ipynotebook/hw2/\"\n",
    "\n",
    "# read file\n",
    "with open( Path + \"News_Final.csv\" , 'r', encoding= 'utf8') as news:\n",
    "    data = csv.reader(news, delimiter = \",\")\n",
    "    listdata = list(data)\n",
    "\n",
    "# change to rdd    \n",
    "subDataset = sc.parallelize(listdata)\n",
    "\n",
    "# remove header\n",
    "header = subDataset.first()\n",
    "subData = subDataset.filter(lambda x: x!=header)\n",
    "\n",
    "# outputfile\n",
    "output_file = \"hw2_4_\"\n",
    "\n",
    "\n",
    "#------------------- Title  -------------------------\n",
    "\n",
    "print(\"Start Title processing\")\n",
    "\n",
    "count_topic_title = subData.map(lambda x: (x[4], x[1]) ).reduceByKey(lambda a, b: a+b)\n",
    "key_topic = count_topic_title.map(lambda x: x[0])\n",
    "\n",
    "for t in range(0, count_topic_title.count()):\n",
    "    topic = key_topic.collect()[t]\n",
    "    \n",
    "    print(\"Start find all row_data in\", topic)\n",
    "    row_data = subData.filter(lambda x: x[4] == topic)\\\n",
    "                         .map( lambda x: re.split(\" \", x[1]))\\\n",
    "                         .map( lambda x : [ re.sub(\"^[^a-zA-Z0-9\\$]\",\"\", i ) for i in x ] )\\\n",
    "                         .map( lambda x : [ re.sub(\"[^a-zA-Z0-9]$\",\"\", i ) for i in x ] )\n",
    "\n",
    "    print(\"Start find top-100 TF in\", topic)\n",
    "    value_topic = row_data.map( lambda x : [ (i,1) for i in x[0:] if(i!='...') if(i!='') ] )\\\n",
    "                          .flatMap(lambda list: list)\\\n",
    "                          .reduceByKey(lambda a, b: a+b).sortBy(lambda x: -x[1]).map(lambda x: x[0])               \n",
    "    top_100 = value_topic.take(100)\n",
    "#     top_100_word = top_100.map(lambda x: x[0])\n",
    "    \n",
    "    \n",
    "    # initial 100x100 matrix                    \n",
    "    Matrix = np.zeros((100,100),int)\n",
    "    \n",
    "    topic_rowdata_count = row_data.count()\n",
    "    topic_top100_count = len(top_100)\n",
    "    topic_rowdata = row_data.collect()\n",
    "#     topic_top100 = top_100.collect()\n",
    "    \n",
    "    print(\"Start processing co-occurrence in \", topic)\n",
    "    for i in range(0, topic_rowdata_count):\n",
    "        for j in range(0, topic_top100_count):\n",
    "            if ((top_100[j]) in (topic_rowdata[i])) :\n",
    "                for k in range(0, topic_top100_count):\n",
    "                    if (top_100[k] in topic_rowdata[i] and j!=k ):\n",
    "                        Matrix[j][k] = Matrix[j][k] + 1\n",
    "    \n",
    "    \n",
    "    print(\"Start output in \", topic)              \n",
    "    with open(output_file + topic + \"_intitle_pertopic.txt\" , 'a') as file:\n",
    "        file.write(\"  \")\n",
    "        for i in range(0, topic_top100_count):\n",
    "            file.write(top_100[i] + \" \")\n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "        for j in range(0, topic_top100_count):\n",
    "            file.write(top_100[j] + \" \")\n",
    "            \n",
    "            for k in range(0, topic_top100_count):\n",
    "                file.write(str(Matrix[j][k]) + \" \")\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "print(\"Title output Success!\")\n",
    "\n",
    "#------------------- headline  -------------------------\n",
    "\n",
    "print(\"Start headline processing\")\n",
    "\n",
    "count_topic_title = subData.map(lambda x: (x[4], x[2]) ).reduceByKey(lambda a, b: a+b)\n",
    "key_topic = count_topic_title.map(lambda x: x[0])\n",
    "\n",
    "for t in range(0, count_topic_title.count()):\n",
    "    topic = key_topic.collect()[t]\n",
    "    \n",
    "    print(\"Start find all row_data in\", topic)\n",
    "    row_data = subData.filter(lambda x: x[4] == topic)\\\n",
    "                         .map( lambda x: re.split(\" \", x[1]))\\\n",
    "                         .map( lambda x : [ re.sub(\"^[^a-zA-Z0-9\\$]\",\"\", i ) for i in x ] )\\\n",
    "                         .map( lambda x : [ re.sub(\"[^a-zA-Z0-9]$\",\"\", i ) for i in x ] )\n",
    "\n",
    "    print(\"Start find top-100 TF in\", topic)\n",
    "    value_topic = row_data.map( lambda x : [ (i,1) for i in x[0:] if(i!='...') if(i!='') ] )\\\n",
    "                          .flatMap(lambda list: list)\\\n",
    "                          .reduceByKey(lambda a, b: a+b).sortBy(lambda x: -x[1]).map(lambda x: x[0])               \n",
    "    top_100 = value_topic.take(100)\n",
    "#     top_100_word = top_100.map(lambda x: x[0])\n",
    "    \n",
    "    \n",
    "    # initial 100x100 matrix                    \n",
    "    Matrix = np.zeros((100,100),int)\n",
    "    \n",
    "    topic_rowdata_count = row_data.count()\n",
    "    topic_top100_count = len(top_100)\n",
    "    topic_rowdata = row_data.collect()\n",
    "#     topic_top100 = top_100.collect()\n",
    "    \n",
    "    print(\"Start processing co-occurrence in \", topic)\n",
    "    for i in range(0, topic_rowdata_count):\n",
    "        for j in range(0, topic_top100_count):\n",
    "            if ((top_100[j]) in (topic_rowdata[i])) :\n",
    "                for k in range(0, topic_top100_count):\n",
    "                    if (top_100[k] in topic_rowdata[i] and j!=k ):\n",
    "                        Matrix[j][k] = Matrix[j][k] + 1\n",
    "    \n",
    "    \n",
    "    print(\"Start output in \", topic)              \n",
    "    with open(output_file + topic + \"_inheadline_pertopic.txt\" , 'a') as file:\n",
    "        file.write(\"  \")\n",
    "        for i in range(0, topic_top100_count):\n",
    "            file.write(top_100[i] + \" \")\n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "        for j in range(0, topic_top100_count):\n",
    "            file.write(top_100[j] + \" \")\n",
    "            \n",
    "            for k in range(0, topic_top100_count):\n",
    "                file.write(str(Matrix[j][k]) + \" \")\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "print(\"Headline output Success!\")\n",
    "print(\"Finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
